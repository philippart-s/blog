---
title: "D√©ployer un site statique sur un bucket S3 avec GitHub Actions"
#excerpt: 
classes: wide
categories:
  - Articles
tags:
  - GitHub
  - S3
   
---
Cela fait quelques temps que j'utilise [GitHub Pages](https://pages.github.com/){:target="_blank"} pour le site de l'association [TADx](https://www.tadx.fr){:target="_blank"} avec [Jekyll](https://jekyllrb.com/){:target="_blank"}.

Et cela fonctionne plut√¥t bien !

Oui mais il me manque quelque chose : un environnement de staging qui me permet de voir ce que donne une modification du site repr√©sent√©e par une branche.
GitHub Pages ne permet pas d'avoir plus d'une branche d√©ploy√©e. 
C'est l√† que je me suis mis √† la recherche d'un endroit o√π d√©ployer le code d'une branche et ce, de mani√®re automatique.
J'ai choisi le couple [bucket S3](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html){:target="_blank"} et [GitHub Actions](https://github.com/features/actions){:target="_blank"} !

## Bucket S3 üì¶
Je ne suis pas un grand sp√©cialiste du cloud et d'AWS, alors pourquoi choisir S3 ? 
Je dois l'avouer que l'on m'a souffl√© l'id√©e suite √† une rencontre avec Laurent Doguin de [Clever Cloud](https://www.clever-cloud.com/){:target="_blank"} lors d'un [meetup](https://www.tadx.fr/2020/11/22/13-eme-event.html){:target="_blank"} TADx. 
Notamment le tr√®s bon [tuto](https://www.clever-cloud.com/blog/engineering/2020/06/24/deploy-cellar-s3-static-site/){:target="_blank"} de Laurent qui explique comment d√©ployer un site statique sur Clever Cloud gr√¢ce √† leur add-on [cellar](https://www.clever-cloud.com/doc/deploy/addon/cellar/){:target="_blank"}.

Du coup, je vous laisse allez regarder tout ce qu'il faut faire pour activer cet add-on, moi je vais juste ajouter deux ou trois trucs pour automatiser tout √ßa :wink:.

## GitHub Actions :rocket:
Une fois le bucket cr√©√© et op√©rationnel il faut l'alimenter, et si possible le plus automatiquement possible pour ne pas avoir √† effectuer toutes les actions √† la main.

### Activer GitHub Actions 
Je ne vais pas m'√©tendre sur ce sujet car, encore une fois, la [documentation](https://docs.github.com/en/free-pro-team@latest/actions){:target="_blank"} est tr√®s bien faite.
Il suffit d'avoir un r√©pertoire `.github/workflows` dans le repository et d'y coller les `.yml` des diff√©rents workflows.

### Automatisation de la cr√©ation du bucket ‚ú®
L'id√©e est de cr√©er un bucket temporaire √† chaque fois qu'une PR est cr√©√©e pour pouvoir visualiser la nouvelle version du site avant de le merger sur la master, cela se fait avec l'action suivante.
```yml
name: Cr√©tion d'un bucket pour la PR

on:
    pull_request:
        types: [opened]
    
jobs:
  create_env:
    name: Cr√©ation du bucket S3 / Cellar
    runs-on: ubuntu-latest
    steps:
      - name: Create bucket for PR
        run: |
            {% raw %}aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
            aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            aws s3api create-bucket --bucket ${{github.head_ref}} --acl public-read --endpoint-url ${{ secrets.CLEVER_END_POINT }} > /dev/null{% endraw %}
```
On voit que ce workflow se d√©clenche sur l'ouverture d'une PR.
Afin de ne pas exposer les secrets Clever ils sont sont stock√©s dans le repository GitHub avec l'utilisation de [GitHub Secrets](https://docs.github.com/en/free-pro-team@latest/actions/reference/encrypted-secrets){:target="_blank"}.

La cr√©ation du bucket va se faire avec le [CLI AWS](https://aws.amazon.com/cli/){:target="_blank"}, comme on n'utilise pas le cloud AWS il faudra sp√©cifier le cellar clever cloud dans toutes les commandes en ajoutant {% raw %}`--endpoint-url ${{ secrets.CLEVER_END_POINT }}`{% endraw %}, l√† encore j'utilise les secrets GitHub pour ne pas indiquer l'URL en dur.

### Mise √† jour du bucket lors du push de code üîÅ
Ici il y a deux √©tapes dans le workflow : builder le site avec Jekyll et le d√©ployer dans le bucket.
{% raw %}
```yml
name: CI / CD des PR

on:
  pull_request:
    branches: [ master ]

jobs:
  jekyll:
    name: Build and deploy Jekyll site
    runs-on: ubuntu-latest

    steps:
    #¬†R√©cup√©ration des sources
    - name: Checkout
      uses: actions/checkout@v2
    # Acivation du cache des d√©pendances Ruby
    - uses: actions/cache@v2
      with:
        path: vendor/bundle
        key: ${{ runner.os }}-gems-${{ hashFiles('**/Gemfile.lock') }}
        restore-keys: |
          ${{ runner.os }}-gems-
    #¬†Build du site Jekyll
    - name: Build
      uses: lemonarc/jekyll-action@1.0.0
    # Copie du site g√©n√©r√© dans le bucket
    - name: Sync output to S3   
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws s3 sync ./_site/ s3://${{github.head_ref}} --endpoint-url ${{ secrets.CLEVER_END_POINT }} --acl public-read
```
{% endraw %}
Ce workflow se d√©clenche √† chaque fois qu'une PR, qui cible la master, a du code qui est push.
Afin d'acc√©l√©rer le build on utilise l'action permettant de faire du [cache de d√©pendance](https://github.com/actions/cache){:target="_blank"} `actions/cache@v2`.

Ensuite j'utilise une action pour [builder](https://github.com/lemonarc/jekyll-action){:target="_blank"} un site Jekyll : `lemonarc/jekyll-action@1.0.0`.
C'est un peu le r√©flexe avec GitHub actions : aller voir sur le [market place](https://github.com/marketplace?type=actions){:target="_blank"} si il n'existe pas d√©j√† une action qui a √©t√© cr√©√©e !
 
Enfin, on synchronise le site dans le bucket, de nouveau on utilise le CLI AWS en indiquant le cellar clever.
 
### Supprimer le bucket üóëÔ∏è

L'id√©e n'est pas de multiplier les versions du site mais simplement d'avoir un environnement de staging √† la demande.
Du coup une fois la PR merg√©e je supprime le bucket.
{% raw %}
```yml
name: Suppression du bucket

on:
    pull_request:
        types: [closed]
    
jobs:
  delete_env:
    name: Suppression du bucket de la branche
    runs-on: ubuntu-latest
    steps:
      - name: Delete bucket for branch
        run: |
            aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
            aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            aws s3 rb s3://${{github.head_ref}} --force --endpoint-url ${{ secrets.CLEVER_END_POINT }}
```
{% endraw %}
Le workflow se d√©clenche √† chaque fermeture de PR.
Rien de sp√©cial, on reprend les m√™mes ingr√©dients que pr√©c√©demment : secrets GitHub et AWS CLI pour la partie bucket.

## En conclusion
Voil√† c'est fini : avec √ßa on a une automatisation qui fonctionne plut√¥t pas mal :wink:.
Il y a des choses √† am√©liorer, comme par exemple publier l'URL du site de test dans la PR mais on a d√©j√† une bonne base. 
C√¥t√© S3 je n'ai pas trop creus√© la chose et j'avoue qu'il y a deux ou trois trucs un peu obscurs :laughing:.
