---
title: "ü§ñL'IA et ses agents, comment √ßa marche ? üîÄ"
description: Mr. Anderson, welcome back. We missed you. ¬© Agent Smith
link: /2026-01-14-ai-agents
image: agent-smith-with-agents-in-the-matrix.jpg
figCaption: ¬© Warner Bros. Pictures
tags: 
  - Code
  - IA
author: wildagsx
---

## üìñ TL;DR
> ü§ñ Les agents sont une des derni√®res nouveaut√©s dans le domaine de l'IA g√©n√©rative.  
> üîÄ Il existe plusieurs moyens de les orchestrer / cha√Æner  
> üßë‚Äçüíª Le code pour illustrer les concepts est en Java (Quarkus / LangChain4j)  
> üêô Le [code source](https://github.com/philippart-s/jarvis) de Jarvis   

<br/>

# üìú Un peu de documentation

On a beaucoup de documentation disponible sur les agents, je vous propose de commencer par ces derni√®res :
 - üìú l'article d'Anthropic [Building effective agents](https://www.anthropic.com/engineering/building-effective-agents)
 - üìö la documentation de LangChain4j sur les [agents](https://docs.langchain4j.dev/tutorials/agents#agentic-systems)
 - üéôÔ∏è l'excellent talk de Guillaume LAFORGE √† TADX : [Agents intelligents, la nouvelle fronti√®re des LLMs](https://youtu.be/0nqxN3fyg1E)
 - üìù de mani√®re plus g√©n√©rale, les [nombreux blog posts](https://glaforge.dev/) de Guillaume üôÇ.

Et bien s√ªr, plein d'autres ressources comme les [replays de Devoxx France](https://www.youtube.com/@DevoxxFRvideos) par exemple.

# üßë‚Äçüè´ Oui mais toi St√©phane, c'est quoi ta d√©finition d'un agent ?

Ah mais nous y voil√† !
En toute honn√™tet√©, j'ai mis pas mal de temps √† comprendre ce qu'√©tait un agent, et surtout en quoi c'√©tait diff√©rent d'un simple appel √† un LLM.
Ce qui n'aide pas non plus, comme souvent avec l'IA, c'est que chaque framework / librairie a sa propre d√©finition d'un agent.
Et comme je n'aime pas ne pas comprendre un truc, je me suis document√©, test√©, pris des murs, et j'ai fini par me faire ma propre d√©finition.
C'est donc celle-ci que je vous propose, en toute humidit√© (comme dirait Perceval ‚öîÔ∏è).

> ‚ö†Ô∏è On est bien d'accord que c'est une d√©finition personnelle, et que je ne pr√©tends pas qu'elle soit universelle.
> √Ä ce titre, n'h√©sitez pas √† me faire des retours si vous n'√™tes pas d'accord. ‚ö†Ô∏è

Si j'√©tais taquin, je dirais, qu'une fois de plus, nos amis dans l'√©cosyst√®me de l'IA ont r√©invent√© une chose vieille comme le monde dans le d√©veloppement logiciel üòà.
En effet, tout le monde s'√©meut autour du fait que l'on a maintenant la capacit√© de faire de petits modules autonomes appelables, potentiellement, par des applications ü§™.
J'en conviens, je suis moqueur, mais apr√®s avoir r√©invent√© les services distants (MCP), l'appel de fonctions utilitaires (function calling), on r√©invente l'approche modulaire avec des agents üôÉ.

## ‚òùÔ∏èÔ∏è Ma d√©finition d'un agent

C'est bien beau de se moquer, mais au final, c'est quoi un agent ?
Un agent va vous permettre de sp√©cialiser l'utilisation d'un LLM pour une t√¢che pr√©cise.

Par exemple, si vous avez une application qui a besoin d'un LLM sp√©cialis√© dans la m√©decine et un autre dans le chinois.
Tout faire avec un seul mod√®le va vous forcer √† utiliser un tr√®s gros mod√®le (donc cher).
Le mod√®le ne sera peut-√™tre pas optimal dans les deux besoins (le fameux dilemme du combi DVD-magn√©toscope üìº).

C'est l√† o√π l'approche agentique va vous permettre de cr√©er des agents sp√©cialis√©s.
Imaginez, que, chaque agent est une mini application (appelez √ßa un microservice si vous voulez üòÜ) qui va encapsuler un LLM avec des prompts, des outils, de la m√©moire, etc. pour r√©pondre √† un besoin pr√©cis.

> ‚ö†Ô∏è Mon analogie avec les microservices peut √™tre trompeuse, car la plupart des agents ne sont pas d√©ploy√©s en tant que services distants, mais ex√©cut√©s localement dans votre application.
> Pour vraiment avoir le m√™me paradigme, il faut utiliser [A2A](https://github.com/a2aproject/A2A) de Google. 
> N'ayant pas jou√© avec A2A, je n'aborderai pas ce sujet dans cet article. ‚ö†Ô∏è

Vous le voyez, la grosse diff√©rence avec un simple appel √† un LLM, c'est que l'agent va encapsuler toute la logique n√©cessaire pour r√©pondre √† un besoin pr√©cis.
Si n√©cessaire, il pourra s'aider d'outils locaux ou distants pour apporter plus de donn√©es dans le traitement de la demande utilisatrice ou utilisateur.

On peut donc, dans un premier temps, r√©sumer l'agent comme ceci : 

![](./simple-agents.png)

Comment interpr√©ter ce merveilleux sch√©ma : 
 - üß© ce sont des briques applicatives qui vont appeler / consommer le retour des agents
 - ü§ñ ce sont mes deux agents
 - üõ†Ô∏è ce sont les outils qu'un agent peut utiliser (dans mon exemple, ils sont locaux, mais ils pourraient √™tre distants)
 - üìú ce sont des donn√©es ajout√©es par l'agent pour enrichir le contexte d'appel du LLM
 - üß† ce sont mes deux Large Language Models (LLM), cela peut √™tre le m√™me selon vos besoins

Je vous l'ai dit, plut√¥t simple.
Les agents ne sont qu'un module applicatif de plus de votre application.
La seule diff√©rence (et non des moindres üòâ), c'est qu'ils se basent sur des LLM.

Ce serait beaucoup trop simple et pas assez waouh dans le monde de l'IA üòÖ.
Si vous lisez 2-3 autres blogs, vous tomberez certainement sur le pattern ReAct pour les agents.
ReAct pour Reasoning and Acting.
L'objectif va √™tre d'introduire une boucle de feedback dans la relation entre votre agent et son LLM.
Ici on va vouloir maximiser la qualit√© de la r√©ponse demand√©e par l'agent.

Si on zoome sur notre agent et son LLM, le pattern ReAct peut se r√©sumer comme suit : 

![](./react-agents.png)

> Si vous voulez en savoir plus (et que vous avez le courage) vous pouvez aller consulter la publication de recherche officielle [ici](https://arxiv.org/pdf/2210.03629).

- L'agent (ü§ñ) envoie la liste des outils (üõ†Ô∏è) et documents potentiellement utilisables par le LLM (üìú), en plus de la demande (prompt)  
- Le LLM commence √† √©laborer son analyse (üí≠) pour r√©pondre au mieux au prompt
- Si besoin, le LLM d√©clenche une nouvelle boucle (üîÅ) d'√©change avec l'agent pour affiner son analyse (demande d'ex√©cutions d'outils ou de donn√©e suppl√©mentaires)  
- Le LLM _estime_ avoir trouv√© la r√©ponse (‚úÖ), elle est renvoy√©e √† l'utilisatrice / utilisateur (ü•≥)  
- alternative : Le LLM ne parvient pas √† aller au bout de son raisonnement (nombre d'it√©rations max atteints ou erreur), une erreur est renvoy√©e (‚ùå)  

## ‚ö†Ô∏è L'importance du prompt dans l'approche agentique

Quel que soit le type d'agent que vous allez cr√©er, le prompt utilis√© sera essentiel.
N'oubliez pas que vous n'√™tes pas dans de l'algorithmique traditionnelle mais que vous d√©l√©guez √† un LLM qui doit savoir quoi faire et pourquoi.
Pour le pattern ReAct c'est m√™me une des composantes primordiales.
Voici un prompt simple pour un agent utilisant le pattern ReAct :
```text
Tu es un agent autonome suivant le pattern ReAct (Reason + Act).

Objectif :
R√©pondre correctement √† la demande de l‚Äôutilisateur.

Tu peux raisonner √©tape par √©tape et utiliser des outils si n√©cessaire.

Outils disponibles :
- <tool_1>(description)
- <tool_2>(description)
- ...

R√®gles de fonctionnement :
1. √Ä chaque √©tape, produis soit :
   - un raisonnement (Thought),
   - soit une action (Action),
   - soit une r√©ponse finale (Final).

2. Si une action est n√©cessaire :
   - indique explicitement l‚Äôaction √† ex√©cuter
   - n‚Äôinvente pas le r√©sultat de l‚Äôaction

3. Apr√®s chaque action, une observation te sera fournie.
   - utilise cette observation pour poursuivre ton raisonnement

4. Lorsque tu estimes avoir suffisamment d‚Äôinformations :
   - produis une r√©ponse finale
   - n‚Äôappelle plus d‚Äôoutil

Format STRICT √† respecter :

Thought: <raisonnement>
Action: <nom_outil>(param√®tres)

ou

Thought: <raisonnement>
Final: <r√©ponse>
```

Ce prompt est tr√®s sch√©matique et certaines actions (comme par exemple la liste d'outils) sont g√©r√©es par les Frameworks (comme [LangChain4J](https://docs.langchain4j.dev/intro/)) par exemple.

## üîÄ Orchestrer, si ... alors ... sinon

Une fois vos agents cr√©√©s, vous allez certainement avoir besoin de les orchestrer.
L√†, vous avez deux approches principales :
1. Faire un workflow classique : boucles, conditions, s√©quences, ex√©cutions parall√®les...
2. D√©l√©guer tout √ßa √† un agent de supervision

Si la premi√®re approche n'est pas tr√®s compliqu√©e √† comprendre (apr√®s tout on fait √ßa depuis des ann√©es dans nos applications).
Je pense qu'un petit √©claircissement de la deuxi√®me n'est pas superflu.
Le but de l'agent superviseur ne va pas √™tre de traiter le prompt mais d'orchestrer au mieux les appels d'agents pour traiter ce prompt.

![](./supervisor-agent.png)

- l'agent superviseur (üëÆ) d√©cide en fonction du prompt quel agent il doit appeler et dans quel ordre
- si tout se passe bien, il commencera par utiliser le bon agent de transport (üöÑ/‚úàÔ∏è/üõ≥Ô∏è) √† appeler
- puis appeler l'agent de paiement (üí∞)

Bien s√ªr, dans cet exemple, vous auriez pu le d√©velopper via un workflow classique.
Mais cela vous permet de voir √† quoi sert un superviseur.

Bon, on est d√©j√† bien avanc√© dans ce post et toujours pas de code ü´£.

# üßë‚Äçüíª Du code !

Allez, c'est parti pour l'impl√©mentation de tout √ßa.
Pour l'impl√©mentation je vais utiliser Python, non je blague üôÉ.
Bien entendu, on va partir avec du Java, [LangChain4J](https://docs.langchain4j.dev/intro/) et [Quarkus](https://quarkus.io/).

Le projet sera celui que j'utilise en conf√©rence pour pr√©senter [Picocli](https://picocli.info/) : [Jarvis](https://github.com/philippart-s/jarvis).

>Si vous voulez plus d'informations sur Picocli je vous laisse aller voir :
> - l'article que j'ai √©crit : [√Ä la d√©couverte de Picocli]({site.url}2023-08-03-discover-picocli)
> - les diff√©rents [replays]({site.url}/talks) de ma conf√©rence sur Picocli 
 
## ü§ñ Cr√©ation des agents

> ‚ÑπÔ∏è √Ä ce stade de mon avanc√©e avec les agents je n'ai pas encore d√©velopp√© un agent suivant le pattern ReAct.
> Vous n'en trouverez donc pas dans le code qui vient. ‚ÑπÔ∏è

La premi√®re chose √† faire va √™tre de cr√©er nos diff√©rents agents.
Pour Jarvis, je vais avoir : 
 - un agent qui doit d√©tecter qu'il faut utiliser des documents externes : `RAGAgent` 
 - un agent qui me permet d'acc√©der √† mon projet public cloud OVHcloud : `OVHcloudAgent`
 - un agent qui doit permettre de r√©pondre √† des questions usuelles : `ChatAgent`

### üìú RagAgent

{|
```java
import dev.langchain4j.agentic.Agent;
import dev.langchain4j.service.SystemMessage;
import dev.langchain4j.service.UserMessage;
import fr.wilda.picocli.sdk.ai.tool.RagTool;
import io.quarkiverse.langchain4j.ToolBox;

public interface RagAgent {

    @SystemMessage("""
            Your are an agent specialized to determine which documents add to RAG.
            If you don't find any information in the user prompt about the path, use DEFAULT as tool parameter.
            Don't try to guess the path, send DEFAULT if you have any doubt.
            Otherwise take only the path and not the file name and return it.
            
            Call the tool that help you to load document in the RAG system.
            """)
    @UserMessage("{userInput}")
    @Agent(description = "This agent should be use when prompt is about to get some information thanks to documents.", outputKey = "agentResponse")
    @ToolBox({RagTool.class})
    String askAQuestionEvent(String userInput);
}
```
|}

On retrouve ici, de mani√®re classique, les `SystemMessage` et `UserMessage`.
L'annotation `@Agent` permet de d√©clarer un agent et non pas juste un chatbot.
En r√©alit√©, c'est tr√®s similaire, c'est juste le mode d'appel qui va √™tre diff√©rent.
Notre agent peut utiliser un outil, `RagTool`, via l'annotation `@ToolBox` 

Ce n'est donc pas cet agent qui r√©pond avec les donn√©es augment√©es par le RAG mais se charge d'aller charger les donn√©es et les mettre √† disposition pour les autres agents.
Comme vous le constatez, gr√¢ce √† LangChain4J et Quarkus (via l'extension [quarkus-langchain4j](https://docs.quarkiverse.io/quarkus-langchain4j/dev/index.html#)), nous sommes en mode d√©claratif via une interface.
Le principal int√©r√™t de cet agent : d√©terminer par rapport au prompt o√π aller chercher les documents n√©cessaires.

{|
```java
import dev.langchain4j.agent.tool.Tool;
import dev.langchain4j.service.V;
import io.quarkus.logging.Log;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;

import java.nio.file.Path;

@ApplicationScoped
public class RagTool {

  @Inject
  DocumentLoader loader;

  @Tool("Load document from the given path into the RAG system")
  void loadDocument(@V("Path to document to load into the RAG system") String path) {
    Log.info(String.format("üìú Loading RAG document from %s%n", path));

    if ("DEFAULT".equals(path)) {
      loader.loadDocument(null);    }
    else {
      loader.loadDocument(Path.of(path));
    }
  }
}
```
|}

Rien de sp√©cial, si ce n'est que pour rendre une m√©thode √©ligible √† √™tre un outil, il suffit de lui ajouter `@Tool` et de bien veiller √† d√©crire ce que doit faire l'outil et les param√®tres qu'il a en entr√©e. 

>Si vous voulez en savoir plus sur le RAG, je vous laisse aller voir mon blog post [ü§ñ Augmente les capacit√©s de ton IA avec LangChain4j ü¶ú]({site.url}/2024-04-14-quarkus-langchain4j-streaming) o√π j'explique comment le mettre en place.

### üõ†Ô∏è OVHcloudAgent
{|
```java
import dev.langchain4j.agentic.Agent;
import dev.langchain4j.service.SystemMessage;
import dev.langchain4j.service.UserMessage;
import fr.wilda.picocli.sdk.ai.tool.TimeAndDateTool;
import io.quarkiverse.langchain4j.ToolBox;
import io.quarkiverse.langchain4j.mcp.runtime.McpToolBox;

public interface OVHcloudAgent {

  @SystemMessage("""
                 You are specialized in OVHcloud products and account access.
                 If a request about OVHcloud resources is asked, use the tools provided for answser.
                 
                 If you don't know how to answer, just reply ‚Äú‚ÅâÔ∏è No data found for {userInput} on OVHcloud project ‚ÅâÔ∏è‚Äù
                 """)
  @UserMessage("{userInput}")
  // ToolBox is, normally not needed, see https://github.com/quarkiverse/quarkus-langchain4j/issues/1581 and https://github.com/quarkiverse/quarkus-langchain4j/issues/1877
  @ToolBox(TimeAndDateTool.class)
  @McpToolBox
  @Agent(description = "Use this agent to have details about OVHcloud products.", outputKey = "agentResponse")
  String askAQuestion(String userInput);
}
```
|}

Cet agent, dans sa construction, ressemble beaucoup au pr√©c√©dent.
La seule diff√©rence est la pr√©sence de l'annotation `@McpToolBox` qui va permettre au mod√®le de demander l'utilisation d'outils distants (disponibles via un serveur MCP).
L'activation d'un client MCP avec Quarkus est tr√®s simple : 

```properties
## MCP parameters
quarkus.langchain4j.mcp.ovhcloud.transport-type=streamable-http
quarkus.langchain4j.mcp.ovhcloud.url=https://mcp.eu.ovhcloud.com/mcp
quarkus.langchain4j.mcp.ovhcloud.log-requests=false
quarkus.langchain4j.mcp.ovhcloud.log-responses=false
```

Si vous ne voyez pas ce qu'est un serveur MCP (pour Model Context Protocol), voyez √ßa comme un service distant que votre LLM peut demander √† √™tre appel√© comme il le fait avec des outils.
Dans le cas d'un appel d'un outil externe dont vous ne ma√Ætrisez pas le code, je vous conseille fortement de demander une validation humaine avant l'ex√©cution de cet outil.
Dans mon cas je n'ai pas envie de supprimer tout mon compte public cloud sur une simple erreur de compr√©hension du LLM üòÖ.

Voici un exemple de comment impl√©menter cette validation humaine :
```java
import dev.langchain4j.agent.tool.ToolSpecification;
import dev.langchain4j.mcp.McpToolExecutor;
import dev.langchain4j.mcp.client.McpClient;
import dev.langchain4j.service.tool.ToolExecutor;
import dev.langchain4j.service.tool.ToolProvider;
import dev.langchain4j.service.tool.ToolProviderRequest;
import dev.langchain4j.service.tool.ToolProviderResult;
import io.quarkus.logging.Log;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.enterprise.inject.Any;
import jakarta.inject.Inject;

import java.util.HashMap;
import java.util.Map;
import java.util.Scanner;

@ApplicationScoped
public class ApprovalMcpToolProvider implements ToolProvider {

  @Inject
  @Any
  McpClient mcpClient;

  @Override
  public ToolProviderResult provideTools(ToolProviderRequest request) {
    Map<ToolSpecification, ToolExecutor> tools = new HashMap<>();
      for (ToolSpecification spec : mcpClient.listTools()) {
        tools.put(spec, (toolRequest, memoryId) -> {
          // Validation
          Log.info(String.format("‚ö†Ô∏è Please valid the tool usage: %s ‚ö†Ô∏è%n", toolRequest.name()));
          Log.info("Please type 'ok' to confirm the use of the tool: ");
          Scanner scanner = new Scanner(System.in);
          if (scanner.next()
              .equals("ok")) {
            Log.info(String.format("üîß Using tool: %s%n",toolRequest.name()));
          } else {
            Log.info(String.format("‚õîÔ∏è User did not validate the use of the tool ‚õîÔ∏è!%n"));
            return "‚õîÔ∏è User did not validate the use of the tool ‚õîÔ∏è!";
          }
          return new McpToolExecutor(mcpClient).execute(toolRequest, memoryId);
        });
      }


    return ToolProviderResult.builder().addAll(tools).build();
  }
}
```
C'est une impl√©mentation tr√®s na√Øve, mais qui permet tout de m√™me de se pr√©munir de fausses manipulations.

### üí¨ JarvisAgent

Le dernier agent est tr√®s simple car c'est celui qui est utilis√© pour simplement avoir un chat bot.
Il a juste la particularit√© de b√©n√©ficier de l'ajout de donn√©es par les agents pr√©c√©dents si n√©cessaire.
{|
```java
import dev.langchain4j.agentic.Agent;
import dev.langchain4j.service.SystemMessage;
import dev.langchain4j.service.UserMessage;
import io.smallrye.mutiny.Multi;

public interface JarvisAgent {
    @SystemMessage("""
             You are a virtual assistant.
             Your goal is to help as best as possible when you are asked a question.
             If you don‚Äôt know how to answer, just reply ‚ÄúI don‚Äôt know how to answer this question.‚Äù
             Answer in a concise and simple way.
            
             If you need more information, you can use information from agents: {agentResponse}
            """)
    @Agent(description = "Chatbot agent that uses data from other agent to have accuracy response.", outputKey = "WFresponse")
    @UserMessage("{userInput}")
    Multi<String> askAQuestion(String userInput, String agentResponse);
}
```
|}
### üîÄ ClassifierAgent
{|
```java
import dev.langchain4j.agentic.Agent;
import dev.langchain4j.service.SystemMessage;
import dev.langchain4j.service.UserMessage;

public interface ClassifierAgent {

    enum SubCommand {
        RAG,
        MCP,
        CHAT
    }

    @SystemMessage("""
                You are a classification system that selects which Jarvis sub-command to call.
                 Given a user question, return ONLY ONE of the following tokens:
                 RAG, MCP, or CHAT
            
                 Classification rules
                    - RAG ‚Üí The question refers to documents, files, PDFs, or phrases like ‚Äúin the document‚Äù, ‚Äúaccording to the file‚Äù
                    - MCP ‚Üí The question is about OVHcloud services, MCP usage, cloud projects, or cloud resources
                    - CHAT ‚Üí Any question that does not match RAG or MCP
            
                 STRICT OUTPUT RULES
                    - Output ONLY the token: RAG, MCP, or CHAT
                    - No explanations
                    - No punctuation
                    - No additional text
                    - No markdown
            
                 Examples
                    - "Show me my OVHcloud information" ‚Üí MCP
                    - "What does the document say about X?" ‚Üí RAG
                    - "What's the weather like?" ‚Üí CHAT
                    - "How do I create a cloud project?" ‚Üí MCP
                    - "Summarize the PDF content" ‚Üí RAG
                    - "Who is the President of France?" ‚Üí CHAT
            """)
    @UserMessage("{userInput}")
    @Agent(description = "Agent to be used to classify / identify the user request.", outputKey = "subCommand")
    SubCommand classify(String userInput);
}
```
|}
Cet agent doit juste permettre ensuite √† mon workflow de savoir, en fonction du prompt, quel agent va r√©pondre au mieux √† la demande.
Comme vous le constatez, avec LangChain4J, il est possible de typer le retour des LLM.

## üîÄ Orchestration des agents

√Ä ce stade, je peux choisir plusieurs fa√ßons d'orchestrer mes agents.
De la plus manuelle √† la plus automatique.

### üë© Workflow humain

La mani√®re la plus simple, donc, d'orchestrer tout √ßa, est de la faire √† la main avec un bon vieux _si ... alors ... sinon_ üòá.

```java
    //...
    var agentResponse = "";
    var agentToCall = classifierAgent.classify(input);
    switch (agentToCall) {
      case MCP -> {
        Log.info("‚òÅÔ∏è MCP Agent selected ‚òÅÔ∏è");
        agentResponse = ovhcloudAgent.askAQuestion(input);
      }
      case RAG -> {
        Log.info("üìú RAG Agent selected üìú");
        ragAgent.askAQuestionEvent(input);

      }
      case CHAT -> Log.info("Chat Agent selected");
      default -> {

      }
    }
    jarvisAgent.askAQuestion(input, agentResponse);
    //...
```
Cette fa√ßon a le m√©rite d'√™tre simple et claire √† comprendre.
Cela laisse assez peu de moyen de faire √©voluer vos agents sans casser ce code.

### ü§ñ Workflow g√©r√© par un agent

Je vous propose d'utiliser un agent pour g√©rer le workflow.
Comme vous allez le constater, cela reste un workflow pr√©d√©fini mais je vais d√©l√©guer la partie `switch` √† un agent.

```java
import dev.langchain4j.agentic.declarative.ActivationCondition;
import dev.langchain4j.agentic.declarative.ConditionalAgent;
import fr.wilda.picocli.sdk.ai.agent.common.ClassifierAgent;
import fr.wilda.picocli.sdk.ai.agent.common.OVHcloudAgent;
import fr.wilda.picocli.sdk.ai.agent.common.RagAgent;
import io.quarkus.logging.Log;

public interface AvailableAgents {

  @ConditionalAgent(description = "Agent used to determine which type of agent is needed: CHAT, MCP, or RAG.",
      subAgents = {
          OVHcloudAgent.class,
          RagAgent.class,
          ChatAgent.class
      },
      outputKey = "agentResponse"
  )
  String executeAgent(String userInput, ClassifierAgent.SubCommand subCommand);

  @ActivationCondition(OVHcloudAgent.class)
  static boolean activateOVHcloudAgent(ClassifierAgent.SubCommand subCommand) {
    var isActivated = subCommand.equals(ClassifierAgent.SubCommand.MCP);
    if (isActivated) {
      Log.info(String.format("Agent to activate: %s%n",  subCommand));
    }
    return isActivated;
  }

  @ActivationCondition(RagAgent.class)
  static boolean activateRagAgent(ClassifierAgent.SubCommand subCommand) {
    var isActivated = subCommand.equals(ClassifierAgent.SubCommand.RAG);
    if (isActivated) {
      Log.info(String.format("Agent to activate: %s%n",  subCommand));
    }
    return isActivated;
  }

  @ActivationCondition(ChatAgent.class)
  static boolean activateJarvisAgent(ClassifierAgent.SubCommand subCommand) {
    var isActivated = subCommand.equals(ClassifierAgent.SubCommand.CHAT);
    if (isActivated) {
      Log.info(String.format("Agent to activate: %s%n",  subCommand));
    }
    return isActivated;
  }

}
```

C'est donc cet agent qui par le biais de l'annotation `@ConditionalAgent` et les m√©thodes d'activation `activateXXX` va permettre de choisir le bon agent √† appeler. 
Ensuite, la gestion de l'appel des agents est d√©l√©gu√©e √† un autre agent.

>‚ö†Ô∏è En parlant d'agent, je fais, certainement, un abus de langage car cet agent n'utilise pas de LLM pour activer les agents.
> Il se contente de r√©cup√©rer le r√©sultat de l'agent classifier pour ensuite activer ou non un agent ‚ö†Ô∏è

Ensuite, il vous reste √† cr√©er votre workflow en cha√Ænant les appels des agents.

```java
package fr.wilda.picocli.sdk.ai.agent.workflow;

import dev.langchain4j.agentic.declarative.SequenceAgent;
import fr.wilda.picocli.sdk.ai.agent.common.ClassifierAgent;
import fr.wilda.picocli.sdk.ai.agent.common.JarvisAgent;
import io.smallrye.mutiny.Multi;

public interface JarvisWorkflow {

  @SequenceAgent(outputKey = "WFresponse", description = "Jarvis Workflow", subAgents =
      {
          ClassifierAgent.class,
          AvailableAgents.class,
          JarvisAgent.class
      })
  Multi<String> executeJarvisWorkflow(String userInput);

}
```

Dans ce cas le workflow est le suivant : 
1. classification de l'agent √† appeler entre RAG, MCP et CHAT
2. appel de l'agent en fonction de la classification
3. appel de l'agent de chat

Au final l'ex√©cution de tout ce workflow se r√©sume par l'appel de ce dernier agent : `jarvisWorkflow.executeJarvisWorkflow(prompt)`

‚ÑπÔ∏è Vous avez peut-√™tre not√© que depuis le d√©but dans les d√©finitions des agents vous avez l'attribut `outputKey`.
Cet attribut est utilis√© pour le mode workflow agentique (et le suivant) pour stocker la r√©ponse d'un agent avant d'appeler un autre agent qui aurait besoin de r√©cup√©rer ces informations.
On appelle √ßa le contexte agentique. ‚ÑπÔ∏è

### ü§ñ Mode superviseur

Au final, vous vous dites peut-√™tre que devoir expliquer l'ordre par algorithmique cela ne fait pas assez IA et agent.
Tr√®s bien, je vous propose une orchestration o√π tout est g√©r√© par un agent.
C'est ce que l'on appelle le mode superviseur.
{|
```java
import dev.langchain4j.agentic.declarative.SupervisorAgent;
import dev.langchain4j.agentic.declarative.SupervisorRequest;
import dev.langchain4j.agentic.supervisor.SupervisorResponseStrategy;
import dev.langchain4j.service.V;
import fr.wilda.picocli.sdk.ai.agent.common.OVHcloudAgent;
import fr.wilda.picocli.sdk.ai.agent.common.RagAgent;
import fr.wilda.picocli.sdk.ai.agent.workflow.ChatAgent;
import io.smallrye.mutiny.Multi;

public interface AutonomousAgent {
    @SupervisorAgent(subAgents = {ChatAgent.class, RagAgent.class, OVHcloudAgent.class}, outputKey = "response",
        maxAgentsInvocations = 3, responseStrategy = SupervisorResponseStrategy.LAST)
    String ask(@V("userInput") String userInput);

    @SupervisorRequest
    static String request(@V("userInput") String userInput) {
      return "Answer to the following question: " + userInput;
    }
}
```
|}
Le r√¥le de cet agent est de d√©cider, tout seul quel agent appeler en fonction du prompt et du r√©sultat d'autres agents.
On peut limiter le nombre d'appels gr√¢ce √† `maxAgentsInvocations`.

L'appel au final se r√©sume donc √† `agentService.ask(question)`.

>‚ÑπÔ∏è C'est gr√¢ce au champ `description` pr√©sent dans tous les agents que l'agent de supervision va d√©cider quel agent appeler. ‚ÑπÔ∏è
 
**‚ö†Ô∏è Attention √† la consommation ‚ö†Ô∏è**  
En effet, avec les autres types de workflows vous ma√Ætrisez vos appels et vos consommations de tokens.
Avec ce mode, c'est le superviseur qui va d√©cider le nombre d'appels √† faire √† vos agents... attention √† la mauvaise surprise üò¶.

# ü§ó En conclusion

J'ai surtout mis des extraits de code pour que l'article reste digeste.
Si vous voulez le code dans son ensemble, c'est ici que √ßa se passe : [Jarvis](https://github.com/philippart-s/jarvis).

Tout √ßa est tr√®s jeune et tr√®s mouvant, notamment du c√¥t√© des frameworks.
C'est pour cela que, dans mes exemples, il y a des lourdeurs afin de contourner certaines limitations.
Il n'est pas √† en douter que ce code va √©voluer avec le temps gr√¢ce aux am√©liorations constantes de ces frameworks.

La derni√®re √©tape sera d'ajouter un agent utilisant le pattern ReAct dont on a parl√© dans cet article.
LangChain4J permet de d√©clarer un agent de type `@loop`.
Je n'ai pas encore essay√© mais cela semble une bonne base de d√©part pour impl√©menter le pattern ReAct.
Je m'y attellerai certainement dans un prochain article, celui-ci est d√©j√† bien trop long üòÖ. 

Si vous √™tes arriv√©‚Ä¢es jusque-l√† merci de m'avoir lu et s'il y a des coquilles n'h√©sitez pas √† me faire une [issue ou PR](https://github.com/philippart-s/blog) üòä.