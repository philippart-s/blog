---
title: "Cr√©er un op√©rateur Kubernetes en Java pour g√©rer une instance Nginx."
description: "Apr√®s le Hello World ! Allons un peu plus vers de l'Ops avec notre op√©rateur Java."
link: /2021-11-21-java-k8s-operator-nginx
tags: 
  - K8s
  - Java
image: Strips-Hello-world-600-final.jpg
figCaption: "@wildagsx"
author: wilda
---

> üí° Mise √† jour : suite √† la release 2.x du SDK j'ai mis √† jour l'article et le code üòâ 




Lors d'un pr√©c√©dent [article](/2021-11-09-java-k8s-operator) j'ai jet√© les bases de comment d√©velopper un op√©rateur Kubernetes en Java.
Apr√®s la r√©alisation d'un merveilleux _Hello World !_ il me semblait utile d'illustrer un cas d'utilisation plus r√©el et de commencer √† faire des actions utiles pour un Ops dans sa vie de tous les jours.

Je ne m'√©tendrai donc pas sur le comment d√©marrer un projet Java pour √©crire un op√©rateur et comment le packager, pour cela je vous laisse vous replonger dans l'article pr√©c√©dent abordant ces sujets.

## Un Ops dans mon cluster üë∑‚Äç‚ôÇÔ∏è ?

Lors de mon pr√©c√©dent article j'indiquais qu'il √©tait possible de faire faire plus ou moins de choses √† notre op√©rateur, le fameux _mod√®le de maturit√©_ des op√©rateurs.
C'est un niveau (de 1 √† 5) qui indique si l'op√©rateur est capable de faire plus ou moins d'actions automatiques (de l'installation √† bien plus).

Dans cet article je vais vous montrer deux aspects int√©ressants pour un tel op√©rateur : 

 - installer et d√©sinstaller de mani√®re simple / automatique un serveur HTTP Nginx,
 - ajouter une surveillance _ops_ qui permet de red√©ployer le serveur si on a supprim√© (par erreur) le d√©ploiement et donc le serveur Nginx.

Deux fonctionnalit√©s tr√®s simples mais qui vont nous permettre de plus se projeter vers un cas concret d'un op√©rateur (mieux qu'avec un _Hello World !_ üòÖ).

## G√©rer l'installation d'un serveur HTTP Nginx üõ†Ô∏è

### La custom resource definition (CRD) üìù

On est habitu√© maintenant, avant toute chose, pour d√©buter notre op√©rateur on cr√©e la [_custom resource definition_](https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/) (CRD) associ√©e.

C'est maintenant une habitude, mais j'utilise le SDK [java-operator-sdk](https://github.com/java-operator-sdk/java-operator-sdk) pour me faciliter la vie pour initier / coder mon op√©rateur.

Commen√ßons donc par les classes n√©cessaires pour g√©n√©rer le YAML de la CRD.

Notre CRD doit permettre la cr√©ation d'une _custom resource_ avec comme champ utile le nombre de replicas que l'on souhaite.
Pour cela on d√©finit la partie _spec_ de la CRD:

```java
public class NginxInstallerSpec {

    private Integer replicas;

    public Integer getReplicas() {
        return replicas;
    }

    public void setReplicas(Integer replicas) {
        this.replicas = replicas;
    }
}
```

Il ne reste plus qu'√† d√©finir la CRD en elle m√™me : 
```java
@Group("fr.wilda")
@Version("v1")
@ShortNames("ngi")
public class NginxInstallerResource extends CustomResource<NginxInstallerSpec, Void> implements Namespaced {
    
}
```

Un petit `mvn clean compile` et la magie du projet [fabric8](https://github.com/fabric8io/kubernetes-client/) fait le reste :

```yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: nginxinstallerresources.fr.wilda
spec:
  group: fr.wilda
  names:
    kind: NginxInstallerResource
    plural: nginxinstallerresources
    shortNames:
    - ngi
    singular: nginxinstallerresource
  scope: Namespaced
  versions:
  - name: v1
    schema:
      openAPIV3Schema:
        properties:
          spec:
            properties:
              replicas:
                type: integer
            type: object
          status:
            type: object
        type: object
    served: true
    storage: true
```

### Le contr√¥leur, l'√¢me de notre op√©rateur ü§ñ

Rentrons dans le vif du sujet et donnons de l'intelligence √† notre op√©rateur.
Cela se passe dans la classe d√©finissant le contr√¥leur.

La structure du contr√¥leur reste simple :
```java
@ControllerConfiguration
public class NginxInstallerReconciler implements Reconciler<NginxInstallerResource> {
  
    // K8S API utility
    private KubernetesClient k8sClient;
    // Watcher to do some actions when events occurs
    private Watch watch = null;
    
    public NginxInstallerReconciler(KubernetesClient k8sClient) {
        this.k8sClient = k8sClient;
    }

    @Override
    public UpdateControl<NginxInstallerResource> reconcile(NginxInstallerResource resource, Context context) {
        System.out.println("üõ†Ô∏è  Create / update Nginx resource operator ! üõ†Ô∏è");

        // ...

        return UpdateControl.updateResource(resource);
    }

    @Override
    public DeleteControl cleanup(NginxInstallerResource resource, Context context) {
        System.out.println("üíÄ Delete Nginx resource operator ! üíÄ");

        // ...

        return DeleteControl.defaultDelete();
    }

}
```

Pour m√©moire, ce contr√¥leur r√©agit sur la cr√©ation / modification / suppression d'une _custom resource_ (bas√©e sur la CRD d√©finie pr√©c√©demment).
A titre d'exemple voici ce que cela donne pour la cr√©ation d'une instance Nginx avec deux replicas dans le namespace _test-nginx-operator_:
```yaml
apiVersion: "fr.wilda/v1"
kind: NginxInstallerResource
metadata:
  name: nginx-installer
  namespace: test-nginx-operator
spec:
  replicas: 2
```

Avant de d√©velopper la partie g√©rant le d√©ploiement, et pour se simplifier la vie, nous allons utiliser un _deployment.yml_ pour le d√©ploiement de Nginx.
Il aurait √©t√© possible de tout faire en Java mais il y a peu d'int√©r√™t ici.

Le _deployment.yml_ pour notre Nginx :
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:stable-alpine
        ports:
        - containerPort: 80
```

Passons au code qui va g√©rer _l'installation_ (en fait la cr√©ation de la ressource de d√©ploiement):
```java
    @Override
    public UpdateControl<NginxInstallerResource> reconcile(NginxInstallerResource resource, Context context) {
        System.out.println("üõ†Ô∏è  Create / update Nginx resource operator ! üõ†Ô∏è");

        String namespace = resource.getMetadata().getNamespace();

        // Load the Nginx deployment
        Deployment deployment = loadYaml(Deployment.class, "/k8s/nginx-deployment.yml");

        // Apply the number of replicas
        deployment.getSpec().setReplicas(resource.getSpec().getReplicas());
        deployment.getMetadata().setNamespace(namespace);
        // Create or update the modifications
        k8sClient.apps().deployments().inNamespace(namespace).createOrReplace(deployment);

        return UpdateControl.updateResource(resource);
    }
```
Et enfin celui qui aura la charge de supprimer notre serveur HTTP :
```java
    @Override
    public DeleteControl cleanup(NginxInstallerResource resource, Context context) {
        System.out.println("üíÄ Delete Nginx resource operator ! üíÄ");

        // Delete deployment and its PODs
        k8sClient.apps().deployments().inNamespace(resource.getMetadata().getNamespace()).delete();

        return DeleteControl.defaultDelete();
    }
```

Simple non ?
Comme indiqu√©, j'ai choisi de partir d'un YAML plut√¥t que de tout renseigner √† la main mais il est possible de tout faire via l'API, on a un exemple avec le positionnement du replica `deployment.getSpec().setReplicas(resource.getSpec().getReplicas());`.

Passons au d√©ploiement de notre op√©rateur et √† son test.

Pour simplifier le test nous allons utiliser le mode ligne de commande : cela correspond √† lancer notre op√©rateur directement depuis l'IDE ou un bash sur notre machine et non d√©ploy√© comme POD dans Kubernetes.
J'ai d√©j√† abord√© le d√©ploiement d'un op√©rateur dans Kubernetes dans mon article pr√©c√©dent. 
J'y reviendrai tout de m√™me en fin d'article car il y a quelques sp√©cificit√©s √† prendre en compte.

Lan√ßons notre op√©rateur et commen√ßons √† tester tout √ßa !

```bash
mvn exec:java -Dexec.mainClass=fr.wilda.NginxInstallerRunner

üöÄ Starting NginxInstaller operator !!! üöÄ
```
Pour tester son bon fonctionnement nous allons commencer par cr√©er la CRD : `kubectl apply -f ./target/classes/META-INF/fabric8/nginxinstallerresources.fr.wilda-v1.yml`.
Enfin il suffit ensuite de cr√©er la CR bas√©e sur la CRD : `kubectl apply -f ./src/test/resources/test_nginx.yml -n test-nginx-operator`.

V√©rifions ce qu'il se passe sur notre op√©rateur et dans notre cluster Kubernetes :
```bash
üöÄ Starting NginxInstaller operator !!! üöÄ
üõ†Ô∏è   Create / update Nginx resource operator ! üõ†Ô∏è
```
```bash
kubectl get pods -n test-nginx-operator

NAME                                READY   STATUS    RESTARTS   AGE
nginx-deployment-69c78cd8c6-bbhjj   1/1     Running   0          107s
nginx-deployment-69c78cd8c6-rz6xs   1/1     Running   0          11s
```
Plut√¥t cool non ?
Nos deux PODs contenant un serveur Nginx ont bien √©t√© d√©ploy√©s comme demand√© !

Et la suppression n'est pas plus compliqu√©e : `kubectl delete ngi/nginx-installer  -n test-nginx-operator`

```bash
üöÄ Starting NginxInstaller operator !!! üöÄ
üõ†Ô∏è   Create / update Nginx resource operator ! üõ†Ô∏è
üíÄ Delete Nginx resource operator ! üíÄ
```
```bash
kubectl get pods -n test-nginx-operator

No resources found in test-nginx-operator namespace.
```

A ce stade de notre d√©veloppement r√©sumons ce que l'on a : 
 - une _custom resource d√©finition_ (CRD) d√©finissant un ressource permettant la cr√©ation d'une _custom resource_ (CR) qui d√©finit les informations minimums (dans notre cas le nombre de r√©plicas) pour cr√©er un POD ou des PODs avec un serveur HTTP Nginx
 - un op√©rateur ayant un contr√¥leur se basant sur la CR cr√©√©e afin de cr√©er ou supprimer les √©l√©ments voulus (les PODs).

C'est bien mais √ßa demande un peu plus d'intelligence, c'est ce que nous allons voir dans le paragraphe suivant !

## Plus d'intelligence !!! üß†

Nous allons donc aller un peu plus loin : 
 - permettre d'utiliser le serveur Nginx d√©ploy√© (c'est la moindre des choses üòÖ) en ajoutant un service (en mode _node port_),
 - ajouter une _supervision_ de notre _deployment_ : si il est supprim√© autrement que via la CR, on le recr√©e.


### Un Ops dans le code üë∑

Nous commen√ßons par ce dernier point : recr√©er le _deployment_ si il est supprim√© par inadvertence.
Pour cela on va utiliser une deuxi√®me notion des op√©rateurs : la notion de _watch_.
C'est assez simple : on va abonner notre op√©rateur √† certains √©v√®nements et il r√©agira en fonction.
Dans notre exemple cela va donner quelque chose du genre : 
> envoie moi tous les √©v√®nements en rapport aux d√©ploiements d'un certain namespace.

Voyons comment faire cela en adaptant notre code pr√©c√©dent et, comme vous vous en doutez peut √™tre, tout va se faire dans le contr√¥leur.
Il suffit d'ajouter dans la m√©thode _createOrUpdateResource_ la gestion des √©v√®nements sur le deployment cr√©√© :

```java
    @Override
    public UpdateControl<NginxInstallerResource> reconcile(NginxInstallerResource resource, Context context) {
        System.out.println("üõ†Ô∏è  Create / update Nginx resource operator ! üõ†Ô∏è");

        String namespace = resource.getMetadata().getNamespace();

        // Load the Nginx deployment
        Deployment deployment = loadYaml(Deployment.class, "/k8s/nginx-deployment.yml");

        // Apply the number of replicas
        deployment.getSpec().setReplicas(resource.getSpec().getReplicas());
        deployment.getMetadata().setNamespace(namespace);
        // Create or update the modifications
        k8sClient.apps().deployments().inNamespace(namespace).createOrReplace(deployment);

        // Watch events on the Nginx deployment
        watch = k8sClient.apps().deployments().withName(deployment.getMetadata().getName())
                .watch(new Watcher<Deployment>() {
                    @Override
                    public void eventReceived(Action action, Deployment resource) {
                        System.out.println("‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è " + action.name());

                        if (action == Action.DELETED) {
                            System.out.println("üóëÔ∏è  Deployment deleted, recreate it ! üóëÔ∏è");
                            k8sClient.apps().deployments().inNamespace(resource.getMetadata().getNamespace())
                                    .createOrReplace(deployment);
                        }
                    }

                    @Override
                    public void onClose(WatcherException cause) {
                        System.out.println("‚ò†Ô∏è Watcher closed due to unexpected error : " + cause);
                    }
                });

        return UpdateControl.updateResource(resource);
    }

```
Ce qui nous int√©resse se trouve dans la m√©thode _watch_ : on r√©cup√®re l'√©v√®nement pour tester si il est de type _DELETE_ afin de recr√©er le _deployment_ que l'on vient de supprimer.

Cela donne en ex√©cutant l'op√©rateur : 
```bash
mvn exec:java -Dexec.mainClass=fr.wilda.NginxInstallerRunner

üöÄ Starting NginxInstaller operator !!! üöÄ
üõ†Ô∏è   Create / update Nginx resource operator ! üõ†Ô∏è
‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è ADDED
‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è MODIFIED
‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è MODIFIED
‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è MODIFIED
```
```bash
 kubectl get pods -n test-nginx-operator
NAME                                READY   STATUS    RESTARTS   AGE
nginx-deployment-69c78cd8c6-5g5kq   1/1     Running   0          3s
nginx-deployment-69c78cd8c6-6t7dx   1/1     Running   0          3s
```

On supprime le deployment sans passer par la suppression de la CR : `kubectl delete deployment/nginx-deployment -n test-nginx-operator`

V√©rifions ce que √ßa a provoqu√© c√¥t√© op√©rateur:
```bash
‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è DELETED
üóëÔ∏è  Deployment deleted, recreate it ! üóëÔ∏è
‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è ADDED
‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è MODIFIED
‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è MODIFIED
‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è MODIFIED
‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è MODIFIED
‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è MODIFIED
‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è MODIFIED
```
Et enfin dans notre cluster:
```bash
 kubectl get pods -n test-nginx-operator
NAME                                READY   STATUS    RESTARTS   AGE
nginx-deployment-64d8d4556f-nrhdw   1/1     Running   0          115s
nginx-deployment-64d8d4556f-zftlf   1/1     Running   0          115s
```

On a bien notre Ops qui veille au grain et recr√©e notre _deployment_ en cas de disparition de celui-ci !

Si vous avez bien suivi il nous reste un derni√®re adaptation √† faire.
En effet, notre ops est un peu trop z√©l√© car m√™me si on supprime la ressource il va recr√©er le _deployment_ !
Pour cela, il faut lui dire d'arr√™ter de surveiller notre _deployment_ en cas de suppression de la CR:
```java
    @Override
    public DeleteControl cleanup(NginxInstallerResource resource, Context context) {
        System.out.println("üíÄ Delete Nginx resource operator ! üíÄ");

        // Avoid the automatic recreation
        if (watch != null) watch.close();
        // Delete deployment and its PODs
        k8sClient.apps().deployments().inNamespace(resource.getMetadata().getNamespace()).delete();

        return DeleteControl.defaultDelete();
    }
```
C'est _close_ sur le _watch_ qui nous permet de dire √† notre ops de se rendormir tranquillement üòâ.

### Terminer la configuration üõ†Ô∏è

Nous venons de fournir √† notre op√©rateur un ops virtuel mais son premier travail, √† savoir l'installation, n'est pas complet.
Notre serveur Nginx n'est pas accessible de l'ext√©rieur.
Pour cela, je rajoute un _service_  en mode _node port_ pour se simplifie la vie (√† ne pas reproduire chez vous !).
Comme pour le _deployment_ je passe par un fichier _yaml_ mais il est possible de tout faire en version code.

Le _service_ : 
```yaml
apiVersion: v1
kind: Service
metadata:
  name: "nginx-service"
spec:
  selector:
    app: "nginx"
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: NodePort
```

Enfin l'adaptation de notre contr√¥leur pour cr√©er ces deux ressources :
```java
    @Override
    public UpdateControl<NginxInstallerResource> reconcile(NginxInstallerResource resource, Context context) {
        System.out.println("üõ†Ô∏è  Create / update Nginx resource operator ! üõ†Ô∏è");
    
        String namespace = resource.getMetadata().getNamespace();

        String namespace = resource.getMetadata().getNamespace();

        // Load the Nginx deployment
        Deployment deployment = loadYaml(Deployment.class, "/k8s/nginx-deployment.yml");

        // Apply the number of replicas
        deployment.getSpec().setReplicas(resource.getSpec().getReplicas());
        deployment.getMetadata().setNamespace(namespace);
        // Create or update the modifications
        k8sClient.apps().deployments().inNamespace(namespace).createOrReplace(deployment);

        // Watch events on the Nginx deployment
        watch = k8sClient.apps().deployments().withName(deployment.getMetadata().getName())
                .watch(new Watcher<Deployment>() {
                    @Override
                    public void eventReceived(Action action, Deployment resource) {
                        System.out.println("‚ö° Event receive on watcher ! ‚ö° ‚û°Ô∏è " + action.name());

                        if (action == Action.DELETED) {
                            System.out.println("üóëÔ∏è  Deployment deleted, recreate it ! üóëÔ∏è");
                            k8sClient.apps().deployments().inNamespace(resource.getMetadata().getNamespace())
                                    .createOrReplace(deployment);
                        }
                    }

                    @Override
                    public void onClose(WatcherException cause) {
                        System.out.println("‚ò†Ô∏è Watcher closed due to unexpected error : " + cause);
                    }
                });

        // Create service
        Service service = loadYaml(Service.class, "/k8s/nginx-service.yml");
        k8sClient.services().inNamespace(namespace).createOrReplace(service);

        return UpdateControl.updateResource(resource);
    }

```
Comme on peut le constater cela reprend exactement le m√™me principe que pour le _deployment_ mais ici on cr√©e notre service.

Testons tout √ßa : 
![Hello world](nginx-welcome.png)


## D√©ploiement dans Kubernetes üê≥

On a un op√©rateur qui a plus d'intelligence que notre simple _Hello World_ du dernier article.
Bien s√ªr ce n'est pas les fonctionnalit√©s les plus impressionnantes du monde mais maintenant que le principe est l√† on peut faire un peut tout type d'action.

Il nous reste une derni√®re chose, le d√©ployer de mani√®re autonome sur notre cluster Kubernetes.
Et l√†, j'ai eu une mauvaise surprise qui m'a occup√©e quelques jours, je vais vous la partager afin de vous faire gagner du temps !

### Le _deployment_ de l'op√©rateur üìù

Avant de passer √† la cr√©ation de l'image (et ses d√©boires) il faut cr√©er le _deployment_ pour notre op√©rateur, rien de bien extraordinaire : 
```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: nginx-operator
---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-operator
  namespace: nginx-operator
spec:
  selector:
    matchLabels:
      app: nginx-operator
  replicas: 1 
  strategy:
    type: Recreate 
  template:
    metadata:
      labels:
        app: nginx-operator
    spec:
      containers:
      - name: operator
        image: localhost:5000/nginx-operator
        imagePullPolicy: Always
```

### A l'uber jar au revoir tu diras üç±

Pour packager et d√©ployer mon op√©rateur j'√©tais parti sur la m√™me chose que pour mon _Hello World_ : Dockerfile et _uber jar_ (ou _fat jar_).
Mais voil√† rien n'est simple dans la vie et une fois mon image d√©ploy√©e dans un POD, mon op√©rateur refusait syst√©matiquement de passer les commandes _fabric8_ pour cr√©er le _deployment_ avec l'erreur : 
```bash
üöÄ Starting NginxInstaller operator !!! üöÄ
üõ†Ô∏è  Create / update Nginx resource operator ! üõ†Ô∏è
07:45:58.215 ERROR io.javaoperatorsdk.operator.processing.EventDispatcher.handleExecution(EventDispatcher.java:55) - Error during event processing ExecutionScope{ events=[CustomResourceEvent{ action=MODIFIED, resource=[ name=nginx-installer, kind=NginxInstallerResource, apiVersion=fr.wilda/v1 ,resourceVersion=274608, markedForDeletion: false ]}], customResource uid: 00ebe0d1-5f22-4982-89bf-fb029b9349d0, version: 274608} failed.
java.lang.IllegalStateException: No adapter available for type:class io.fabric8.kubernetes.client.AppsAPIGroupClient
    at io.fabric8.kubernetes.client.BaseClient.adapt(BaseClient.java:134) ~[operator.jar:?]
    at io.fabric8.kubernetes.client.BaseKubernetesClient.apps(BaseKubernetesClient.java:523) ~[operator.jar:?]
    at fr.wilda.controller.NginxInstallerController.createOrUpdateResource(NginxInstallerController.java:46) ~[operator.jar:?]
    at fr.wilda.controller.NginxInstallerController.createOrUpdateResource(NginxInstallerController.java:20) ~[operator.jar:?]
    at io.javaoperatorsdk.operator.processing.ConfiguredController$2.execute(ConfiguredController.java:101) ~[operator.jar:?]
    at io.javaoperatorsdk.operator.processing.ConfiguredController$2.execute(ConfiguredController.java:76) ~[operator.jar:?]
    at io.javaoperatorsdk.operator.Metrics.timeControllerExecution(Metrics.java:23) ~[operator.jar:?]
    at io.javaoperatorsdk.operator.processing.ConfiguredController.createOrUpdateResource(ConfiguredController.java:75) ~[operator.jar:?]
    at io.javaoperatorsdk.operator.processing.EventDispatcher.handleCreateOrUpdate(EventDispatcher.java:127) ~[operator.jar:?]
    at io.javaoperatorsdk.operator.processing.EventDispatcher.handleDispatch(EventDispatcher.java:87) ~[operator.jar:?]
    at io.javaoperatorsdk.operator.processing.EventDispatcher.handleExecution(EventDispatcher.java:46) [operator.jar:?]
    at io.javaoperatorsdk.operator.processing.DefaultEventHandler$ControllerExecution.run(DefaultEventHandler.java:360) [operator.jar:?]
    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
    at java.lang.Thread.run(Unknown Source) [?:?]
```

Apr√®s quelques heures / jours de recherches j'ai mis en doute mon image elle-m√™me (il m'en a fallu du temps me direz vous ! üòÖ), j'ai donc d√©cid√© d'utiliser la m√™me technique que dans les exemples de l'op√©rateur, √† savoir le plugin maven [jib](https://github.com/GoogleContainerTools/jib/tree/master/jib-maven-plugin) pour fabriquer l'image.

```xml
    <plugins>
      <plugin>
        <groupId>com.google.cloud.tools</groupId>
        <artifactId>jib-maven-plugin</artifactId>
        <version>3.2.0</version>
        <configuration>
          <from>
            <image>adoptopenjdk:11-jre</image>
          </from>
          <to>
            <image>localhost:5000/nginx-operator</image>
          </to>
        </configuration>
      </plugin>
```

Un petit coup de maven : `mvn clean compile jib:dockerBuild`

Et l√† magie cela fonctionne du premier coup !

Si une personne a une explication j'avoue que je suis preneur car √† ce stade je ne vois pas l'explication.
Ca sent un probl√®me de pr√©c√©dence dans le _classpath_ mais je n'arrive pas √† mettre le doigt dessus !

## Conclusion üßê

Avec cet exemple un peu plus pouss√© j'esp√®re que vous avez pu entrevoir toutes les possibilit√©s d'un op√©rateur et sa facilit√© de l'√©crire en Java.

L'ensemble des sources est disponible dans le projet GitHub [java-k8s-nginx-operator](https://github.com/philippart-s/java-k8s-nginx-operator).

Merci de m'avoir lu et si vous avez vu des coquilles n'h√©sitez pas √† me l'indiquer sur le repository des [sources](https://github.com/philippart-s/java-k8s-nginx-operator) ou de l'[article](https://github.com/philippart-s/blog).